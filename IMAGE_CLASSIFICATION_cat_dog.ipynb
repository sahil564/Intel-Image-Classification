{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395c8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f17087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the datasets directories\n",
    "\n",
    "train_path = '/home/sahil/Desktop/applied.ai/computer vision/folder/data/training_set'\n",
    "test_path = '/home/sahil/Desktop/applied.ai/computer vision/folder/data/training_set'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f03682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07a166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea30f08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dogs', 'cats']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf64a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some basic parameters\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3024af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19013e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a744c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loading function\n",
    "\n",
    "def load_data(path, labels):\n",
    "    dataset = image_dataset_from_directory(\n",
    "        directory=path,\n",
    "        labels=labels,\n",
    "        seed=123,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4305ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 files belonging to 2 classes.\n",
      "Found 8005 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "\n",
    "train_ds = load_data(train_path, labels='inferred')\n",
    "test_ds = load_data(test_path, labels='inferred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829d10b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'dogs']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the image labels\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1ede4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first nine images from the training dataset\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77531cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5d919",
   "metadata": {},
   "source": [
    "# Standardize the Data\n",
    "The RGB channel values are in the [0, 255] range. This is not ideal for a neural network.\n",
    "\n",
    "The values should be standardized to be in the [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee4db626",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Rescaling' from 'keras.layers' (/home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-668c41167800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRescaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscaling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRescaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Rescaling' from 'keras.layers' (/home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/keras/layers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Rescaling\n",
    "scaling = Rescaling(1. / 255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (scaling(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (scaling(x), y))\n",
    "# pred_ds = pred_ds.map(lambda x: scaling(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d7477",
   "metadata": {},
   "source": [
    "# Create Simple CNN Model (sCNN)\n",
    "The Sequential model consists of three convolution blocks with a max pooling layer in each of them.\n",
    "\n",
    " There's a fully-connected layer with 128 units on top of it that is activated by a ReLU activation function ('relu').\n",
    "\n",
    "This model is a simple model and has not been tuned for high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94cc8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sCNN = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fbc9a0",
   "metadata": {},
   "source": [
    "# Compile the ModelÂ¶\n",
    "The Compile method configures the model for training and validation using the optimizer, loss function, and evaluation metrics.\n",
    "\n",
    "This workflow will use the Adam optimizer, the Sparse Categorical Crossentropy loss function, and the Accuracy evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d238b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sCNN.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fe441ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2654336   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,678,178\n",
      "Trainable params: 2,678,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b811d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = sCNN.fit(train_ds, validation_data=test_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570acbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "sCNN_loss, sCNN_acc = sCNN.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0c03d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf13e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('cat-dog1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466289e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "sCNN_loss, sCNN_acc = new_model.evaluate(test_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23719750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/home/sahil/Desktop/applied.ai/computer vision/folder/data/test_set/cats/cat.4001.jpg', target_size = (64, 64))\n",
    "# Loading the image and converting the pixels into array whcih will be used as input to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa38875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F62B3AF51F0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b369868",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85dde81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 150, 150, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 64, 64, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 20736 but received input with shape (None, 4096)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-85d0b5dd18b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3357\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3277\u001b[0m           expand_composites=True)\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 20736 but received input with shape (None, 4096)\n"
     ]
    }
   ],
   "source": [
    "result=new_model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70929235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 150, 150, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 64, 64, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 20736 but received input with shape (None, 4096)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-166403e4f450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:375 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424 call\n        return self._run_internal_graph(\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/sahil/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:255 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 20736 but received input with shape (None, 4096)\n"
     ]
    }
   ],
   "source": [
    "result = new_model.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= Sequential() # Initialise the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afeb95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ist step of Convoltional layer to get feature maps using feature detector\n",
    "classifier.add(Convolution2D(filters=32, # output feature maps\n",
    "                             kernel_size=(3,3), # matrix size for feature detector\n",
    "                             input_shape=(64, 64, 3), # input image shape, 3 is for rgb coloured image with 128*128 px\n",
    "                             kernel_initializer='he_uniform', # weights distriution\n",
    "                             activation='relu')) # activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa64cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd Pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd convolutional and pooling layer.\n",
    "classifier.add(Convolution2D(filters=32,\n",
    "                             kernel_size=(3,3), \n",
    "                             kernel_initializer='he_uniform', \n",
    "                             activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d823d",
   "metadata": {},
   "source": [
    "\n",
    "in case we dont do do convolutional and pooiling and directly flatten our input image pixel and pass it , out network wont be able to find the relations between each pixels and will treat each pixel indiviually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1255af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 full connection in which input we have from flattening\n",
    "\n",
    "classifier.add(Dense(units=128,kernel_initializer='glorot_uniform', activation='relu')) \n",
    "#step 5 output layer\n",
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e5741",
   "metadata": {},
   "source": [
    "Fitting the model\n",
    "In this we first need to do image augmentation using kera image preprocessing modules. It is necessary to to avoid the overfitting when we have less data to train which leat to high training accuracy and low testing accuracy.\n",
    "\n",
    "In this we will make different batches of sub samples , in each batch it will have random transformations like rotating, shifting and flipping which will add diversity to data and being random our model wont get same image to get trained on.\n",
    "\n",
    "This will help us in high performance with no overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad182392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce95d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying all the transformation we want to apply to training data set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf407b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescling the test data set images to use for validation.\n",
    "test_datagen= ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51041ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting My training data ready for validation, so it will read all the data with the px size we gave.\n",
    "\n",
    "training_set= train_datagen.flow_from_directory(directory= 'dataset/training_set',\n",
    "                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n",
    "                                               batch_size=50,\n",
    "                                               class_mode='binary' # for 2 class binary \n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting My test data ready for validation, so it will read all the data with the px size we gave.\n",
    "\n",
    "test_set= test_datagen.flow_from_directory(directory= 'dataset/test_set',\n",
    "                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n",
    "                                               batch_size=50,\n",
    "                                               class_mode='binary' # for 2 class binary\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416019ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier.fit_generator(training_set, #training data to fit\n",
    "                        steps_per_epoch=8000, # Data in training set\n",
    "                        epochs=5, # No of epochs to run\n",
    "                        validation_data=test_set, # Test or validation set\n",
    "                        validation_steps=2000 # no of data point for validation\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "# Loading the image and converting the pixels into array whcih will be used as input to predict.\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
