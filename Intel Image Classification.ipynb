{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368b3dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some basic parameters\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7792c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the datasets directories\n",
    "\n",
    "train_path = '/home/sahil/Desktop/applied.ai/computer vision/folder/seg_train'\n",
    "test_path = '/home/sahil/Desktop/applied.ai/computer vision/folder/seg_test'\n",
    "pred_path = '/home/sahil/Desktop/applied.ai/computer vision/folder/seg_pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6ec5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63368882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8e30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loading function\n",
    "\n",
    "def load_data(path, labels):\n",
    "    dataset = image_dataset_from_directory(\n",
    "        directory=path,\n",
    "        labels=labels,\n",
    "        seed=123,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6667b72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Found 3000 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "\n",
    "train_ds = load_data(train_path, labels='inferred')\n",
    "test_ds = load_data(test_path, labels='inferred')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d1a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the image labels\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810d7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first nine images from the training dataset\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b801387",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e77e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "# pred_ds = pred_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbcdd82",
   "metadata": {},
   "source": [
    "# Standardize the Data\n",
    "The RGB channel values are in the [0, 255] range. This is not ideal for a neural network.\n",
    "\n",
    "The values should be standardized to be in the [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c895d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f95913",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = Rescaling(1. / 255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (scaling(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (scaling(x), y))\n",
    "# pred_ds = pred_ds.map(lambda x: scaling(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10331349",
   "metadata": {},
   "source": [
    "# Create Simple CNN Model (sCNN)\n",
    "The Sequential model consists of three convolution blocks with a max pooling layer in each of them.\n",
    "\n",
    "There's a fully-connected layer with 128 units on top of it that is activated by a ReLU activation function ('relu').\n",
    "\n",
    "This model is a simple model and has not been tuned for high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9562e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sCNN = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8689a8",
   "metadata": {},
   "source": [
    "# Compile the Model\n",
    "The Compile method configures the model for training and validation using the optimizer, loss function, and evaluation metrics.\n",
    "\n",
    "This workflow will use the Adam optimizer, the Sparse Categorical Crossentropy loss function, and the Accuracy evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72dc1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sCNN.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6896a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2654336   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,678,694\n",
      "Trainable params: 2,678,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27/439 [>.............................] - ETA: 51:55 - loss: 136.2324 - accuracy: 0.1751"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "history = sCNN.fit(train_ds, validation_data=test_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c655450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sCNN.save(\"model_intel_classification\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
